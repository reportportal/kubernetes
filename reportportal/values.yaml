## String to partially override reportportal.fullname template (will maintain the release name)
##
# nameOverride:

## String to fully override reportportal.fullname template
##
# fullnameOverride:

serviceindex:
  repository: reportportal/service-index
  tag: 5.8.0
  name: index
  pullPolicy: Always
  resources:
    requests:
      cpu: 150m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi
  podLabels: {}
  podAnnotations: {}
  securityContext: {}
  ## Define which Nodes the Pods are scheduled on.
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  #  disktype: ssd
  service:
    portName: ""

uat:
  repository: reportportal/service-authorization
  tag: 5.8.0
  name: uat
  pullPolicy: Always
  readinessProbe:
    enabled: true
    initialDelaySeconds: 60
    periodSeconds: 40
    timeoutSeconds: 5
    failureThreshold: 10
  livenessProbe:
    enabled: true
    initialDelaySeconds: 60
    periodSeconds: 40
    timeoutSeconds: 5
    failureThreshold: 10
  resources:
    requests:
      cpu: 100m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 2048Mi
  sessionLiveTime: 86400
  samlSessionLiveTime: 4320
  ## The initial password for superadmin user on FIRST launch. If the password was changed from the UI, 
  ## this value can't change the password on redeployments.
  superadminInitPasswd:
    ## If 'true', the secret will be generated from 20 random characters.
    auto: false
    ## Specify if auto = false
    password: "erebus"
  podLabels: {}
  podAnnotations: {}
  ## jvmArgs
  ## If you need to use a custom java keystore you can use it through jvmArgs
  ## eg. : -Djavax.net.ssl.trustStore=/etc/secret-volume/custom-pki.jks 
  jvmArgs: "-Djava.security.egd=file:/dev/./urandom -XX:MinRAMPercentage=60.0 -XX:MaxRAMPercentage=90.0"
  ## External environment variables
  ##
  extraEnvs: []
    # - name: EXTRA_ENV
    #   value: "TRUE"
    # - name: EXTRA_ENV_SECRET
    #   valueFrom:
    #     secretKeyRef:
    #       name: "additional-credentials"
    #       key: username
  securityContext: {}
  ## Define which Nodes the Pods are scheduled on.
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  #  disktype: ssd
  serviceAccountName: ""
  ## Provide a secret containing sensitives data
  ## EG.: provide a custom java keystore used in jvmArgs
  ##
  ## keytool -genkeypair -storetype jks -alias todelete -keypass changeit -storepass changeit -keystore custom-pki.jks -dname "CN=Developer, OU=Department, O=Company, L=City, ST=State, C=CA"
  ## keytool -delete -alias todelete -storepass changeit -keystore custom-pki.jks
  ## keytool -list -keystore custom-pki.jks -storepass changeit
  ## 
  ## Generate base64 data and paste it in your values.yaml :
  ## cat custom-pki.jks | base64 -w 
  secret:
    enabled: false
    mountPath: /etc/secret-volume
    readOnly: true
    data: {}
    #  custom-pki.jks: <base64-data>
  service:
    portName: ""

serviceui:
  repository: reportportal/service-ui
  tag: 5.8.0
  name: ui
  pullPolicy: Always
  resources:
    requests:
      cpu: 100m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 128Mi
  podLabels: {}
  podAnnotations: {}
  securityContext: {}
  ## Define which Nodes the Pods are scheduled on.
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  #  disktype: ssd
  serviceAccountName: ""
  service:
    portName: ""

serviceapi:
  repository: reportportal/service-api
  tag: 5.8.0
  name: api
  pullPolicy: Always
  replicaCount: 1
  readinessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 20
    timeoutSeconds: 3
    failureThreshold: 20
  livenessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 20
    timeoutSeconds: 5
    failureThreshold: 5
  resources:
    requests:
      cpu: 500m
      memory: 1024Mi
    limits:
      cpu: 1000m
      memory: 2048Mi
  ## jvmArgs
  ## If you need to use a custom java keystore you can use it through jvmArgs
  ## eg. : -Djavax.net.ssl.trustStore=/etc/secret-volume/custom-pki.jks 
  jvmArgs: "-Djava.security.egd=file:/dev/./urandom -XX:+UseG1GC -XX:MinRAMPercentage=60.0 -XX:InitiatingHeapOccupancyPercent=70 -XX:MaxRAMPercentage=90.0 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp"
  ## Number of queues
  ## Where "totalNumber" is the total number of queues
  ## Ð¡alculation formula: perPodNumber = totalNumber / serviceapi.replicaCount
  queues:
    totalNumber:
    perPodNumber:
  ## External environment variables
  ##
  extraEnvs: []
    # - name: EXTRA_ENV
    #   value: "TRUE"
    # - name: EXTRA_ENV_SECRET
    #   valueFrom:
    #     secretKeyRef:
    #       name: "additional-credentials"
    #       key: username
  podLabels: {}
  podAnnotations: {}
  securityContext: {}
  ## Define which Nodes the Pods are scheduled on.
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  #  disktype: ssd
  serviceAccountName: ""
  service:
    portName: ""
  ## Provide a secret containing sensitives data
  ## eg. : provide a custom java keystore used in jvmArgs
  ##
  ## keytool -genkeypair -storetype jks -alias todelete -keypass changeit -storepass changeit -keystore custom-pki.jks -dname "CN=Developer, OU=Department, O=Company, L=City, ST=State, C=CA"
  ## keytool -delete -alias todelete -storepass changeit -keystore custom-pki.jks
  ## keytool -list -keystore custom-pki.jks -storepass changeit
  ## 
  ## Generate base64 data and paste it in your values.yaml :
  ## cat custom-pki.jks | base64 -w 
  secret:
    enabled: false
    mountPath: /etc/secret-volume
    readOnly: true
    data: {}
    #  custom-pki.jks: <base64-data>

servicejobs:
  repository: reportportal/service-jobs
  tag: 5.8.0
  name: jobs
  pullPolicy: Always
  readinessProbe:
    enabled: true
    initialDelaySeconds: 60
    periodSeconds: 40
    timeoutSeconds: 5
    failureThreshold: 10
  livenessProbe:
    enabled: true
    initialDelaySeconds: 60
    periodSeconds: 40
    timeoutSeconds: 5
    failureThreshold: 10
  coreJobs:
    cleanAttachmentCron: 0 0 */24 * * *
    cleanLogCron: 0 0 */24 * * *
    cleanLaunchCron: 0 0 */24 * * *
    cleanStorageCron: 0 0 */24 * * *
    storageProjectCron: 0 */5 * * * *
  chunksize: 1000
  ## Used for Double Entry. Ref: https://reportportal.io/blog/double-entry-in-5.7.2
  ## Processing logs by Jobs service (log per ms).
  logProcessing:
    maxBatchSize: 2000
    maxBatchTimeout: 6000
  resources:
    requests:
      cpu: 100m
      memory: 248Mi
    limits:
      cpu: 100m
      memory: 372Mi
  jvmArgs: ""
  ## External environment variables
  ##
  extraEnvs: []
    # - name: EXTRA_ENV
    #   value: "TRUE"
    # - name: EXTRA_ENV_SECRET
    #   valueFrom:
    #     secretKeyRef:
    #       name: "additional-credentials"
    #       key: username
  podLabels: {}
  podAnnotations: {}
  securityContext: {}
  ## Define which Nodes the Pods are scheduled on.
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  #  disktype: ssd
  serviceAccountName: ""
  service:
    portName: ""

migrations:
  repository: reportportal/migrations
  tag: 5.8.0
  pullPolicy: Always
  resources:
    requests:
      cpu: 100m
      memory: 64Mi
    limits:
      cpu: 100m
      memory: 128Mi
  podLabels: {}
  podAnnotations: {}
  securityContext: {}
  ## Define which Nodes the Pods are scheduled on.
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  #  disktype: ssd
  serviceAccountName: ""
  metadataAnnotations:
    enabled: true
    hooks:
      "helm.sh/hook": post-install,post-upgrade
      "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
      "helm.sh/hook-weight": "-5"

serviceanalyzer:
  repository: reportportal/service-auto-analyzer
  tag: 5.7.5
  name: analyzer
  pullPolicy: Always
  uwsgiWorkers: 2
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 100m
      memory: 512Mi
  podLabels: {}
  podAnnotations: {}
  securityContext: {}
  ## External environment variables
  ##
  extraEnvs: []
    # - name: EXTRA_ENV
    #   value: "TRUE"
    # - name: EXTRA_ENV_SECRET
    #   valueFrom:
    #     secretKeyRef:
    #       name: "additional-credentials"
    #       key: username
  ##
  ## Define which Nodes the Pods are scheduled on.
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  #  disktype: ssd
  serviceAccountName: ""
  service:
    portName: ""

serviceanalyzertrain:
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 200m
      memory: 512Mi
  podLabels: {}
  podAnnotations: {}
  securityContext: {}
  ## External environment variables
  ##
  extraEnvs: []
    # - name: EXTRA_ENV
    #   value: "TRUE"
    # - name: EXTRA_ENV_SECRET
    #   valueFrom:
    #     secretKeyRef:
    #       name: "additional-credentials"
    #       key: username
  ## Define which Nodes the Pods are scheduled on.
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  #  disktype: ssd
  serviceAccountName: ""
  service:
    portName: ""

metricsgatherer:
  repository: reportportal/service-metrics-gatherer
  tag: 5.7.4
  name: metrics-gatherer
  loggingLevel: debug
  timeManagement:
    starttime: 22:00
    endtime: 08:00
    timezone: Europe/Minsk
  maxDaysStore: 500
  resources:
    requests:
      cpu: 8m
      memory: 128Mi
    limits:
      cpu: 16m
      memory: 256Mi
  podLabels: {}
  podAnnotations: {}
  securityContext: {}
  ## External environment variables
  ##
  extraEnvs: []
    # - name: EXTRA_ENV
    #   value: "TRUE"
    # - name: EXTRA_ENV_SECRET
    #   valueFrom:
    #     secretKeyRef:
    #       name: "additional-credentials"
    #       key: username
  ## Define which Nodes the Pods are scheduled on.
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  #  disktype: ssd
  serviceAccountName: ""
  service:
    portName: ""

## Ingress configuration for the ui
## If you have installed ingress controller and want to expose application - set INGRESS.ENABLE to true.
## If you have some domain name set INGRESS.USEDOMAINNAME variable to true and set this fqdn to INGRESS.HOSTS
## If you don't have any domain names - set INGRESS.USEDOMAINNAME to false
ingress:
  enable: true
  ## IF YOU HAVE SOME DOMAIN NAME SET INGRESS.USEDOMAINNAME to true
  usedomainname: false
  hosts:
    - reportportal.k8.com
  class: nginx
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "false"
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/x-forwarded-prefix: /$1
    nginx.ingress.kubernetes.io/proxy-body-size: 128m
    nginx.ingress.kubernetes.io/proxy-buffer-size: 512k
    nginx.ingress.kubernetes.io/proxy-buffers-number: "4"
    nginx.ingress.kubernetes.io/proxy-busy-buffers-size: 512k
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "8000"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "4000"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "4000"
  tls: []
  # - hosts:
  #   - reportportal.k8.com
  #   secretName: reportportal.k8.com-tls

## tolerations for all components, if any (requires Kubernetes >= 1.6)
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
tolerations: []
  # - key: "key"
  #   operator: "Equal|Exists"
  #   value: "value"
  #   effect: "NoSchedule|PreferNoSchedule|NoExecute"

## RBAC is required for service-index in order to collect status/info over all services
rbac:
  create: true
  serviceAccount:
    create: true
    name: reportportal
    ## For AWS IAM role association use the following annotations
    ## See: https://docs.aws.amazon.com/eks/latest/userguide/specify-service-account-role.html
    annotations: {}

rp:
  infoEndpoint: "/info"
  healthEndpoint: "/health"

## Extra init containers to e.g. wait for minio
extraInitContainers: {}
  # - name: "wait-for-minio"
  #   image: "busybox"
  #   imagePullPolicy: "IfNotPresent"
  #   command:
  #     - sh
  #     - "-c"
  #     - "for i in `seq 1 300`; do sleep 1; if wget http://<minio-release-name>-minio.default.svc.cluster.local:9000/minio/health/live -q -O /dev/null ; then exit 0; fi; done; exit 1"

# Infrastructure values

dependencies: &installDep true

postgresql:
  ## Custom values
  install: *installDep
  SecretName: ""
  ## @param postgresql.endpoint By default {{ .Release.Name }}-postgresql.{{ .Release.Namespace }}.svc.cluster.local
  endpoint:
  ssl: disable
  
  ## Overload the default values for the PostgreSQL chart
  postgresqlUsername: postgres
  postgresqlPassword: rppassword
  postgresqlDatabase: reportportal
  servicePort: 5432
  postgresqlMaxConnections: ""

rabbitmq:
  install: *installDep
  SecretName: ""
  ## @param rabbitmq.endpoint By default {{ .Release.Name }}-rabbitmq.{{ .Release.Namespace }}.svc.cluster.local
  endpoint:
  ## Enable HTTPS and AMQPS
  ssl: false 
  ## Virtual hosts provide logical grouping and separation of resources.
  ## ref: https://www.rabbitmq.com/vhosts.html
  vhost: analyzer

  ##  Overload the default values for the RabbitMQ chart
  auth:
    username: rabbitmq
    password: rabbitmq
  containerPorts:
    amqp: 5672
    manager: 15672

minio:
  install: *installDep
  enabled: true
  type: minio
  secretName: ""
  ## @param minio.endpoint By default http://{{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc.cluster.local:9000
  endpoint:
  ## @param minio.endpointshort By default {{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc.cluster.local:9000
  endpointshort:
  region: ""
  accessKey:
    password: &accessKey <minio-accesskey>
  secretKey:
    password: &secretKey <minio-secretkey>
  accesskey: *accessKey
  secretkey: *secretKey
  accesskeyName: "access-key"
  secretkeyName: "secret-key"
  bucketPrefix: ""
  defaultBucketName: ""
  integrationSaltPath: ""

opensearch:
  install: *installDep
  secretName: ""
  doubleEntry: true
  ## @param opensearch.endpoint By default opensearch-cluster-master.{{ .Release.Namespace }}.svc.cluster.local
  endpoint:
  user: admin
  password: admin

  ## Overload the default values for the OpenSearch chart
  ## @param opensearch.singleNode If "true", replicas will be forced from 3 to 1
  singleNode: true
  protocol: http
  httpPort: 9200
  startupProbe:
    initialDelaySeconds: 30
  config:
    opensearch.yml: |
      cluster.name: opensearch-cluster

      # Bind to all interfaces because we don't know what IP address Docker will assign to us.
      network.host: 0.0.0.0

      # Setting network.host to a non-loopback address enables the annoying bootstrap checks. "Single-node" mode disables them again.
      # Implicitly done if ".singleNode" is set to "true".
      # discovery.type: single-node

      # Start OpenSearch Security Demo Configuration
      # WARNING: revise all the lines below before you go into production
      plugins:
        security:
          ssl:
            transport:
              pemcert_filepath: esnode.pem
              pemkey_filepath: esnode-key.pem
              pemtrustedcas_filepath: root-ca.pem
              enforce_hostname_verification: false
            http:
              enabled: false
          allow_unsafe_democertificates: true
          allow_default_init_securityindex: true
          authcz:
            admin_dn:
              - CN=kirk,OU=client,O=client,L=test,C=de
          audit.type: internal_opensearch
          enable_snapshot_restore_privilege: true
          check_snapshot_restore_write_privileges: true
          restapi:
            roles_enabled: ["all_access", "security_rest_api_access"]
          system_indices:
            enabled: true
            indices:
              [
                ".opendistro-alerting-config",
                ".opendistro-alerting-alert*",
                ".opendistro-anomaly-results*",
                ".opendistro-anomaly-detector*",
                ".opendistro-anomaly-checkpoints",
                ".opendistro-anomaly-detection-state",
                ".opendistro-reports-*",
                ".opendistro-notifications-*",
                ".opendistro-notebooks",
                ".opendistro-asynchronous-search-response*",
              ]
      ######## End OpenSearch Security Demo Configuration ########